train_mode: "finetune"

training_model_parameters:
    goal_loss_weight: 1
    collision_loss_weight: 5

data_module_parameters:
  data_dir: /data/ompl_cubby_6k #/data/mpinets_hybrid_training_data_small
  trajectory_key: 'global_solutions' # Could also use 'global_solutions' for the global expert
  num_obstacle_points: 4096
  num_target_points: 128
  random_scale: 0

shared_parameters:
    num_robot_points: 2048

model_path: null # /workspace/mpinets_hybrid_expert.ckpt
checkpoint_interval: 2
validation_interval: 4
gpus: 1 # If > 1, will use DDP for training.
batch_size: 32
save_checkpoint_dir: /workspace/mpinets_finetune
experiment_name: finetune_cubby_6k
description: "finetune training"
